# Embodied Referring Expression Comprehension in Humanâ€“Robot Interaction

This repository hosts the project page and resources for our accepted paper at **ACM/IEEE HRI 2026**.

ğŸ“„ **Paper Title:**  
**Embodied Referring Expression Comprehension in Humanâ€“Robot Interaction**

---

## Resources

### ğŸ“¦ Datasets

**Refer360 Dataset (Processed, 49.71 GB):**  
https://bit.ly/refer360_dataset_processed

<!--
**Refer360 Dataset (Raw, 2572.36 GB):**  
https://bit.ly/refer360_dataset_raw
-->

---

### ğŸ’» Source Code

**Source Code â€“ Refer360 Data Collection System:**  
https://bit.ly/source_code_data_collection_system

**Source Code â€“ MuRes and Baseline Models (8.8 MB):**  
https://bit.ly/source_code_MuGuRu_and_baseline_models

---

### ğŸ§  Model Artifacts

**Trained Model Checkpoints (CLIP + MuRes, 5.4 GB):**  
https://bit.ly/model_checkpoints

---

### ğŸ³ Training Environment

**Docker / Singularity Container for Training (8.59 GB):**

We provide a containerized environment to facilitate easy reproduction of our experimental settings and training pipeline.  
The following Singularity container was built from the Docker image used in our experiments:

https://bit.ly/multimodal-docker
